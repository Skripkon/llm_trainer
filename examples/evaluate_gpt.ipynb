{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb5e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 124.44M\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "print(f\"Parameters: {model.num_parameters() / 10 ** 6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377e5ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 acc_norm: 336/1000=0.3360\n",
      "2000 acc_norm: 673/2000=0.3365\n",
      "3000 acc_norm: 1031/3000=0.3437\n",
      "4000 acc_norm: 1316/4000=0.3290\n",
      "5000 acc_norm: 1594/5000=0.3188\n",
      "6000 acc_norm: 1883/6000=0.3138\n",
      "7000 acc_norm: 2152/7000=0.3074\n",
      "8000 acc_norm: 2413/8000=0.3016\n",
      "9000 acc_norm: 2684/9000=0.2982\n",
      "10000 acc_norm: 2957/10000=0.2957\n",
      "10042 acc_norm: 2968/10042=0.2956\n"
     ]
    }
   ],
   "source": [
    "from llm_trainer import Evaluator\n",
    "\n",
    "evaluator = Evaluator()\n",
    "evaluator.evaluate(model,               # Evaluate GPT-2 SMALL (124M)\n",
    "                   tokenizer,           # Use the same tokenizer as was used to train GPT-2\n",
    "                   \"hellaswag\",         # Use HellaSwag Benchmark\n",
    "                   return_logits=False, # GPT-2 model from transformers returns an object with an attribute .logits\n",
    "                   verbose=1000         # Print accuracy after each 1000 samples\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6b895",
   "metadata": {},
   "source": [
    "### HellaSwag accuracy is 29.56% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
