{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download some text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to /home/nick/.cache/kagglehub/datasets/paultimothymooney/poetry/versions/16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import kagglehub  # pip install kagglehub\n",
    "\n",
    "# Download files with song lyrics from Kaggle.\n",
    "# Save them to `lyrics_path`\n",
    "lyrics_path = kagglehub.dataset_download(\"paultimothymooney/poetry\")\n",
    "print(f\"Data downloaded to {lyrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 .txt files downloaded.\n"
     ]
    }
   ],
   "source": [
    "lyrics_files = os.listdir(lyrics_path)\n",
    "print(f\"{len(lyrics_files)} .txt files downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r-kelly.txt', 'amy-winehouse.txt', 'adele.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert text files to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory `json_files`\n",
    "os.makedirs(\"json_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lyrics_file in lyrics_files:\n",
    "\n",
    "    with open(file=os.path.join(lyrics_path, lyrics_file), mode=\"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    temp_dict = [{\"text\": text}]\n",
    "    json_path = os.path.join(\"json_files\", lyrics_file)\n",
    "\n",
    "    json_path = json_path[:-4] + \".json\" # remove .txt and add .json\n",
    "    with open(json_path, 'w') as fp:\n",
    "        json.dump(temp_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Chunks:   1%|          | 18/1500 [00:00<01:12, 20.41chunk/s]\n"
     ]
    }
   ],
   "source": [
    "from llm_trainer import create_dataset_from_json\n",
    "\n",
    "create_dataset_from_json(save_dir=\"data\",\n",
    "                         json_dir=\"json_files\",\n",
    "                         chunk_size=int(1e5),\n",
    "                         chunk_limit=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GPT2 model on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel(config=GPT2Config(n_positions=256, n_embd=512, n_head=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | Loss: 11.000000 | norm: 14.4398 | lr: 2.000000e-05 | dt: 9.04s | tok/sec: 7251.91\n",
      "step: 1 | Loss: 10.125000 | norm: 6.9708 | lr: 2.666667e-05 | dt: 1.53s | tok/sec: 42769.15\n",
      "step: 2 | Loss: 10.000000 | norm: 4.0215 | lr: 3.333333e-05 | dt: 1.53s | tok/sec: 42750.91\n",
      "step: 3 | Loss: 9.937500 | norm: 3.1104 | lr: 4.000000e-05 | dt: 1.53s | tok/sec: 42806.98\n",
      "step: 4 | Loss: 9.875000 | norm: 2.6609 | lr: 4.666667e-05 | dt: 1.53s | tok/sec: 42789.87\n",
      "step: 5 | Loss: 9.937500 | norm: 3.0117 | lr: 5.333333e-05 | dt: 1.53s | tok/sec: 42813.61\n",
      "step: 6 | Loss: 9.625000 | norm: 3.0445 | lr: 6.000000e-05 | dt: 1.53s | tok/sec: 42874.80\n",
      "step: 7 | Loss: 9.687500 | norm: 2.3515 | lr: 6.666667e-05 | dt: 1.53s | tok/sec: 42789.31\n",
      "step: 8 | Loss: 9.687500 | norm: 2.0178 | lr: 7.333333e-05 | dt: 1.53s | tok/sec: 42793.26\n",
      "step: 9 | Loss: 9.687500 | norm: 5.9197 | lr: 8.000000e-05 | dt: 1.53s | tok/sec: 42825.83\n",
      "step: 10 | Loss: 9.562500 | norm: 2.3708 | lr: 8.666667e-05 | dt: 1.53s | tok/sec: 42812.49\n",
      "step: 11 | Loss: 9.625000 | norm: 2.2498 | lr: 9.333333e-05 | dt: 1.53s | tok/sec: 42839.34\n",
      "step: 12 | Loss: 9.500000 | norm: 2.7553 | lr: 1.000000e-04 | dt: 1.53s | tok/sec: 42839.91\n",
      "step: 13 | Loss: 9.562500 | norm: 2.2314 | lr: 1.066667e-04 | dt: 1.53s | tok/sec: 42852.83\n",
      "step: 14 | Loss: 9.625000 | norm: 2.2107 | lr: 1.133333e-04 | dt: 1.53s | tok/sec: 42800.46\n",
      "step: 15 | Loss: 9.250000 | norm: 2.4250 | lr: 1.200000e-04 | dt: 1.53s | tok/sec: 42876.89\n",
      "step: 16 | Loss: 9.000000 | norm: 2.6515 | lr: 1.266667e-04 | dt: 1.53s | tok/sec: 42928.64\n",
      "step: 17 | Loss: 9.062500 | norm: 2.1120 | lr: 1.333333e-04 | dt: 1.53s | tok/sec: 42882.42\n",
      "step: 18 | Loss: 9.062500 | norm: 1.9217 | lr: 1.400000e-04 | dt: 1.53s | tok/sec: 42823.10\n",
      "step: 19 | Loss: 9.000000 | norm: 2.0377 | lr: 1.466667e-04 | dt: 1.53s | tok/sec: 42843.17\n",
      "step: 20 | Loss: 8.937500 | norm: 2.1300 | lr: 1.533333e-04 | dt: 1.53s | tok/sec: 42758.05\n",
      "step: 21 | Loss: 8.937500 | norm: 2.2250 | lr: 1.600000e-04 | dt: 1.53s | tok/sec: 42793.19\n",
      "step: 22 | Loss: 8.750000 | norm: 2.6317 | lr: 1.666667e-04 | dt: 1.53s | tok/sec: 42698.92\n",
      "step: 23 | Loss: 8.625000 | norm: 2.8875 | lr: 1.733333e-04 | dt: 1.53s | tok/sec: 42734.55\n",
      "step: 24 | Loss: 8.812500 | norm: 2.1254 | lr: 1.800000e-04 | dt: 1.53s | tok/sec: 42819.31\n",
      "step: 25 | Loss: 8.500000 | norm: 1.9067 | lr: 1.866667e-04 | dt: 1.53s | tok/sec: 42754.12\n",
      "step: 26 | Loss: 8.312500 | norm: 1.9698 | lr: 1.933333e-04 | dt: 1.53s | tok/sec: 42734.12\n",
      "step: 27 | Loss: 8.312500 | norm: 1.8064 | lr: 2.000000e-04 | dt: 1.53s | tok/sec: 42756.27\n",
      "step: 28 | Loss: 8.000000 | norm: 1.7032 | lr: 2.066667e-04 | dt: 1.54s | tok/sec: 42483.56\n",
      "step: 29 | Loss: 8.062500 | norm: 2.0064 | lr: 2.133333e-04 | dt: 1.54s | tok/sec: 42624.30\n",
      "step: 30 | Loss: 8.000000 | norm: 1.6301 | lr: 2.200000e-04 | dt: 1.54s | tok/sec: 42669.83\n",
      "step: 31 | Loss: 8.000000 | norm: 1.6899 | lr: 2.266667e-04 | dt: 1.54s | tok/sec: 42671.99\n",
      "step: 32 | Loss: 8.062500 | norm: 1.5859 | lr: 2.333333e-04 | dt: 1.53s | tok/sec: 42733.79\n",
      "step: 33 | Loss: 7.437500 | norm: 2.1294 | lr: 2.400000e-04 | dt: 1.54s | tok/sec: 42679.52\n",
      "step: 34 | Loss: 7.375000 | norm: 1.8868 | lr: 2.466667e-04 | dt: 1.53s | tok/sec: 42718.65\n",
      "step: 35 | Loss: 7.406250 | norm: 2.1439 | lr: 2.533333e-04 | dt: 1.53s | tok/sec: 42701.54\n",
      "step: 36 | Loss: 7.531250 | norm: 2.7710 | lr: 2.600000e-04 | dt: 1.53s | tok/sec: 42889.61\n",
      "step: 37 | Loss: 7.093750 | norm: 2.1288 | lr: 2.666667e-04 | dt: 1.52s | tok/sec: 43022.28\n",
      "step: 38 | Loss: 7.218750 | norm: 1.1347 | lr: 2.733333e-04 | dt: 1.52s | tok/sec: 43004.32\n",
      "step: 39 | Loss: 7.000000 | norm: 1.1543 | lr: 2.800000e-04 | dt: 1.53s | tok/sec: 42937.18\n",
      "step: 40 | Loss: 6.875000 | norm: 1.1186 | lr: 2.866667e-04 | dt: 1.53s | tok/sec: 42924.94\n",
      "step: 41 | Loss: 6.687500 | norm: 1.3996 | lr: 2.933333e-04 | dt: 1.53s | tok/sec: 42944.43\n",
      "step: 42 | Loss: 6.718750 | norm: 1.0618 | lr: 3.000000e-04 | dt: 1.53s | tok/sec: 42839.40\n",
      "step: 43 | Loss: 6.906250 | norm: 1.4123 | lr: 3.066667e-04 | dt: 1.54s | tok/sec: 42621.33\n",
      "step: 44 | Loss: 6.718750 | norm: 0.9445 | lr: 3.133333e-04 | dt: 1.55s | tok/sec: 42377.86\n",
      "step: 45 | Loss: 7.406250 | norm: 5.2340 | lr: 3.200000e-04 | dt: 1.54s | tok/sec: 42683.73\n",
      "step: 46 | Loss: 6.468750 | norm: 1.1567 | lr: 3.266667e-04 | dt: 1.54s | tok/sec: 42624.59\n",
      "step: 47 | Loss: 6.625000 | norm: 0.6828 | lr: 3.333333e-04 | dt: 1.54s | tok/sec: 42660.01\n",
      "step: 48 | Loss: 6.031250 | norm: 1.2419 | lr: 3.400000e-04 | dt: 1.54s | tok/sec: 42692.78\n",
      "step: 49 | Loss: 6.593750 | norm: 1.5171 | lr: 3.466667e-04 | dt: 1.53s | tok/sec: 42723.15\n",
      "step: 50 | Loss: 6.781250 | norm: 1.4304 | lr: 3.533333e-04 | dt: 1.53s | tok/sec: 42884.23\n",
      "step: 51 | Loss: 6.500000 | norm: 1.8844 | lr: 3.600000e-04 | dt: 1.53s | tok/sec: 42782.17\n",
      "step: 52 | Loss: 6.593750 | norm: 1.7161 | lr: 3.666667e-04 | dt: 1.53s | tok/sec: 42758.14\n",
      "step: 53 | Loss: 6.625000 | norm: 1.2879 | lr: 3.733333e-04 | dt: 1.53s | tok/sec: 42846.27\n",
      "step: 54 | Loss: 5.937500 | norm: 1.9428 | lr: 3.800000e-04 | dt: 1.53s | tok/sec: 42783.47\n",
      "step: 55 | Loss: 6.187500 | norm: 1.8725 | lr: 3.866667e-04 | dt: 1.53s | tok/sec: 42890.79\n",
      "step: 56 | Loss: 6.656250 | norm: 3.1974 | lr: 3.933333e-04 | dt: 1.53s | tok/sec: 42935.89\n",
      "step: 57 | Loss: 6.250000 | norm: 1.3144 | lr: 4.000000e-04 | dt: 1.52s | tok/sec: 43138.06\n",
      "step: 58 | Loss: 6.593750 | norm: 1.4786 | lr: 4.066667e-04 | dt: 1.52s | tok/sec: 43005.15\n",
      "step: 59 | Loss: 6.406250 | norm: 1.1181 | lr: 4.133333e-04 | dt: 1.52s | tok/sec: 43056.65\n",
      "step: 60 | Loss: 6.281250 | norm: 4.7179 | lr: 4.200000e-04 | dt: 1.54s | tok/sec: 42524.86\n",
      "step: 61 | Loss: 6.125000 | norm: 2.3807 | lr: 4.266667e-04 | dt: 1.54s | tok/sec: 42641.00\n",
      "step: 62 | Loss: 6.187500 | norm: 2.1687 | lr: 4.333333e-04 | dt: 1.54s | tok/sec: 42669.96\n",
      "step: 63 | Loss: 6.343750 | norm: 2.7631 | lr: 4.400000e-04 | dt: 1.54s | tok/sec: 42621.51\n",
      "step: 64 | Loss: 6.312500 | norm: 1.4512 | lr: 4.466667e-04 | dt: 1.53s | tok/sec: 42694.88\n",
      "step: 65 | Loss: 6.312500 | norm: 1.0172 | lr: 4.533333e-04 | dt: 1.54s | tok/sec: 42617.56\n",
      "step: 66 | Loss: 6.343750 | norm: 1.5810 | lr: 4.600000e-04 | dt: 1.53s | tok/sec: 42701.58\n",
      "step: 67 | Loss: 6.187500 | norm: 2.6737 | lr: 4.666667e-04 | dt: 1.53s | tok/sec: 42812.79\n",
      "step: 68 | Loss: 6.000000 | norm: 1.9705 | lr: 4.733333e-04 | dt: 1.53s | tok/sec: 42893.34\n",
      "step: 69 | Loss: 7.000000 | norm: 2.2891 | lr: 4.800000e-04 | dt: 1.53s | tok/sec: 42973.31\n",
      "step: 70 | Loss: 6.593750 | norm: 1.2457 | lr: 4.866667e-04 | dt: 1.53s | tok/sec: 42893.80\n",
      "step: 71 | Loss: 6.593750 | norm: 1.9439 | lr: 4.933333e-04 | dt: 1.53s | tok/sec: 42925.95\n",
      "step: 72 | Loss: 6.625000 | norm: 1.6726 | lr: 5.000000e-04 | dt: 1.54s | tok/sec: 42613.03\n",
      "step: 73 | Loss: 6.531250 | norm: 4.3181 | lr: 5.066667e-04 | dt: 1.54s | tok/sec: 42629.82\n",
      "step: 74 | Loss: 6.500000 | norm: 2.9218 | lr: 5.133333e-04 | dt: 1.54s | tok/sec: 42595.99\n",
      "step: 75 | Loss: 6.062500 | norm: 2.1485 | lr: 5.200000e-04 | dt: 1.54s | tok/sec: 42608.87\n",
      "step: 76 | Loss: 6.031250 | norm: 3.2600 | lr: 5.266667e-04 | dt: 1.54s | tok/sec: 42503.67\n",
      "step: 77 | Loss: 6.093750 | norm: 2.4882 | lr: 5.333333e-04 | dt: 1.54s | tok/sec: 42551.98\n",
      "step: 78 | Loss: 6.218750 | norm: 1.8099 | lr: 5.400000e-04 | dt: 1.55s | tok/sec: 42405.86\n",
      "step: 79 | Loss: 6.125000 | norm: 1.4474 | lr: 5.466667e-04 | dt: 1.54s | tok/sec: 42607.03\n",
      "step: 80 | Loss: 5.937500 | norm: 2.1222 | lr: 5.533333e-04 | dt: 1.55s | tok/sec: 42253.20\n",
      "step: 81 | Loss: 6.156250 | norm: 1.8698 | lr: 5.600000e-04 | dt: 1.55s | tok/sec: 42275.00\n",
      "step: 82 | Loss: 5.937500 | norm: 1.1053 | lr: 5.666667e-04 | dt: 1.55s | tok/sec: 42254.22\n",
      "step: 83 | Loss: 5.843750 | norm: 1.6445 | lr: 5.733333e-04 | dt: 1.54s | tok/sec: 42445.41\n",
      "step: 84 | Loss: 6.375000 | norm: 1.4998 | lr: 5.800000e-04 | dt: 1.54s | tok/sec: 42533.06\n",
      "step: 85 | Loss: 6.062500 | norm: 2.0162 | lr: 5.866667e-04 | dt: 1.54s | tok/sec: 42613.35\n",
      "step: 86 | Loss: 5.875000 | norm: 1.6719 | lr: 5.933333e-04 | dt: 1.55s | tok/sec: 42374.28\n",
      "step: 87 | Loss: 5.875000 | norm: 1.5990 | lr: 6.000000e-04 | dt: 1.54s | tok/sec: 42642.93\n",
      "step: 88 | Loss: 6.250000 | norm: 1.5714 | lr: 6.066667e-04 | dt: 1.53s | tok/sec: 42698.43\n",
      "step: 89 | Loss: 6.437500 | norm: 1.7696 | lr: 6.133333e-04 | dt: 1.53s | tok/sec: 42741.88\n",
      "step: 90 | Loss: 6.156250 | norm: 1.4853 | lr: 6.200000e-04 | dt: 1.53s | tok/sec: 42770.85\n",
      "step: 91 | Loss: 6.187500 | norm: 2.1145 | lr: 6.266667e-04 | dt: 1.54s | tok/sec: 42653.76\n",
      "step: 92 | Loss: 6.000000 | norm: 2.6382 | lr: 6.333333e-04 | dt: 1.53s | tok/sec: 42712.01\n",
      "step: 93 | Loss: 6.562500 | norm: 2.2850 | lr: 6.400000e-04 | dt: 1.53s | tok/sec: 42897.53\n",
      "step: 94 | Loss: 6.093750 | norm: 2.1453 | lr: 6.466667e-04 | dt: 1.53s | tok/sec: 42903.18\n",
      "step: 95 | Loss: 5.843750 | norm: 1.3336 | lr: 6.533333e-04 | dt: 1.53s | tok/sec: 42925.40\n",
      "step: 96 | Loss: 5.375000 | norm: 1.6640 | lr: 6.600000e-04 | dt: 1.56s | tok/sec: 41978.19\n"
     ]
    }
   ],
   "source": [
    "from llm_trainer import LLMTrainer\n",
    "\n",
    "trainer = LLMTrainer(model=model)\n",
    "trainer.train(generate_each_n_steps=100, max_steps=200, prompt=\"Every time we say goodbye,\\nI die a little\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DISPLAY LOSS\n",
    "data = pd.read_csv(\"logs_training.csv\")\n",
    "\n",
    "window_size = 10  # Adjust for more or less smoothing\n",
    "smoothed_loss = data[\"Loss\"].rolling(window=window_size).mean()\n",
    "\n",
    "plt.plot(data[\"Step\"], smoothed_loss, label=\"Smoothed Loss\", color=\"pink\")\n",
    "plt.plot(data[\"Step\"], data[\"Loss\"], alpha=0.5, label=\"Original Loss\", color=\"gray\")\n",
    "\n",
    "plt.axhline(y=6, color='r', linestyle='--', alpha=0.6)\n",
    "plt.axhline(y=5, color='gray', linestyle='--', alpha=0.6)\n",
    "plt.axhline(y=4, color='y', linestyle='--', alpha=0.6)\n",
    "plt.axhline(y=3, color='g', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
